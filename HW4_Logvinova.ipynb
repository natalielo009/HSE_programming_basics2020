{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "def tokenize(s):\n",
    "    \"\"\"Break str s into a list of strings according to some procedure \n",
    "    tailored for the task at hand.\"\"\"\n",
    "    #your code\n",
    "    words = ''\n",
    "    p = list(punctuation)\n",
    "    for i in range(len(s)):\n",
    "        if s[i] in p:\n",
    "            continue\n",
    "        words = words + s[i]\n",
    "    phrase = str(words)\n",
    "    spltd = phrase.split()\n",
    "    return spltd\n",
    "def gutenberg_file_wc(filename):\n",
    "    \"\"\"Open the file with name filename, tokenize it with your \n",
    "    tokenize function, and return a dict mapping words to their \n",
    "    counts in the file.  Tokenize only the material that occurs\n",
    "    between the two lines given above.\"\"\"\n",
    "    #insert your code here\n",
    "    wc = {}\n",
    "    alice = open('alice.txt').read()\n",
    "    a = alice.find(\"I--DOWN THE RABBIT-HOLE\") \n",
    "    z = alice.find(\"*** END OF THIS PROJECT GUTENBERG EBOOK\") \n",
    "    alice_new = alice[a:z].lower()\n",
    "    alice_tokens = tokenize(alice_new)\n",
    "    for i in alice_tokens:\n",
    "        token_count = alice_tokens.count(i)\n",
    "        wc[i] = token_count\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tw': 1, 'sl': 1, 'st': 1, 'pl': 1, 'tr': 3, 'cl': 1, 'fl': 1, 'str': 2, 'fr': 1, 'gr': 1, 'dr': 2, 'gl': 3, 'sm': 1, 'br': 1, 'thr': 1, 'pr': 1, 'cr': 1, 'sc': 1, 'sp': 1, 'spl': 1, 'sk': 2, 'shr': 1, 'sw': 1, 'spr': 2, 'sn': 1, 'scr': 1, 'sq': 1, 'bl': 2, 'wr': 1}\n",
      "The total number of clusters was 38\n",
      "The alphabetical order of clusters is: ['bl', 'br', 'cl', 'cr', 'dr', 'fl', 'fr', 'gl', 'gr', 'pl', 'pr', 'sc', 'scr', 'shr', 'sk', 'sl', 'sm', 'sn', 'sp', 'spl', 'spr', 'sq', 'st', 'str', 'sw', 'thr', 'tr', 'tw', 'wr']\n"
     ]
    }
   ],
   "source": [
    "initial_cluster_counted = {}\n",
    "list_of_digraphs = ['ch', 'sh', 'th', 'wh', 'ph', 'kn', 'dg', 'dj', 'gh', 'gn', 'ss']\n",
    "tokenized = (tokenize (open('alice.txt').read()))\n",
    "words_counted = list(gutenberg_file_wc(tokenized).items())\n",
    "for words in words_counted:\n",
    "    initial_cluster = re.search('^[bcdfghjklmnpqrstvwxz]{2,}', words[0])\n",
    "    if type(initial_cluster) == type(None):\n",
    "        pass\n",
    "    else:\n",
    "        initial_cluster1 = initial_cluster.group()\n",
    "        if initial_cluster1 in list_of_digraphs:\n",
    "            pass\n",
    "        else:\n",
    "            initial_cluster_counted[initial_cluster1] = words[1]\n",
    "number_of_clusters = sum(initial_cluster_counted.values())\n",
    "all_clusters = sorted(initial_cluster_counted.keys())\n",
    "print(initial_cluster_counted)\n",
    "print ('The total number of clusters was', number_of_clusters)\n",
    "print('The alphabetical order of clusters is:', all_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Final Project Idea\n",
    "\n",
    "I want to create a small corpus of chuvash publicistic texts by crawling the texts published on the sites of local chuvash newspapers and magazines. Then, based on the data of my corpus, I want to study the discourse usage of the 3rd person possessive marker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
